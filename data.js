const glossaryTerms = [
    {
        "term": "Artificial Intelligence",
        "definition": "A field of computer science focused on creating systems capable of performing tasks that require human intelligence."
    },
    {
        "term": "Machine Learning",
        "definition": "A subset of AI that uses algorithms to parse data, learn from it, and make predictions or decisions without being explicitly programmed."
    },
    {
        "term": "Neural Network",
        "definition": "A series of algorithms that mimic the human brain to recognize patterns and relationships in data."
    },
    {
        "term": "Deep Learning",
        "definition": "A subset of machine learning that uses layered neural networks to analyze data with a high level of complexity."
    },
    {
        "term": "Natural Language Processing (NLP)",
        "definition": "A field of AI that enables computers to understand, interpret, and generate human language."
    },
    {
        "term": "Computer Vision",
        "definition": "A field of AI focused on enabling machines to interpret and make decisions based on visual data."
    },
    {
        "term": "Reinforcement Learning",
        "definition": "A type of machine learning where an agent learns by interacting with an environment to maximize some cumulative reward."
    },
    {
        "term": "Supervised Learning",
        "definition": "A machine learning approach where models are trained on labeled data to make predictions."
    },
    {
        "term": "Unsupervised Learning",
        "definition": "A machine learning technique that analyzes and clusters unlabeled data to find hidden patterns or structures."
    },
    {
        "term": "Semi-Supervised Learning",
        "definition": "A machine learning method that combines a small amount of labeled data with a large amount of unlabeled data during training."
    },
    {
        "term": "Feature Extraction",
        "definition": "The process of transforming raw data into numerical features that can be processed while maintaining the information in the original data set."
    },
    {
        "term": "Gradient Descent",
        "definition": "An optimization algorithm used to minimize the loss function in machine learning and deep learning models."
    },
    {
        "term": "Overfitting",
        "definition": "A modeling error that occurs when a model learns the training data too well, including noise, making it less effective on new data."
    },
    {
        "term": "Underfitting",
        "definition": "A situation where a machine learning model is too simple to capture the patterns in the data, resulting in poor performance."
    },
    {
        "term": "Activation Function",
        "definition": "A function applied to each node in a neural network to determine whether it should activate or not based on weighted input."
    },
    {
        "term": "Backpropagation",
        "definition": "A training algorithm for neural networks that calculates gradients and adjusts weights to minimize errors."
    },
    {
        "term": "Convolutional Neural Network (CNN)",
        "definition": "A type of neural network commonly used in computer vision, specifically designed to process pixel data."
    },
    {
        "term": "Recurrent Neural Network (RNN)",
        "definition": "A type of neural network that processes sequential data by maintaining a memory of previous inputs."
    },
    {
        "term": "Generative Adversarial Network (GAN)",
        "definition": "A class of machine learning frameworks in which two networks compete, leading to improved data generation results."
    },
    {
        "term": "Transfer Learning",
        "definition": "A technique where a model developed for a particular task is reused as a starting point for a model on a second task."
    },
    {
        "term": "Data Augmentation",
        "definition": "A technique used to increase the diversity of training data by applying transformations like rotation, flipping, or cropping."
    },
    {
        "term": "Hyperparameter",
        "definition": "Parameters in machine learning algorithms that are set before training and control the learning process, such as learning rate and batch size."
    },
    {
        "term": "Epoch",
        "definition": "One complete pass through the entire training dataset by a machine learning algorithm."
    },
    {
        "term": "Tokenization",
        "definition": "The process of splitting text into smaller pieces, usually words or phrases, that can be used as inputs for NLP models."
    },
    {
        "term": "Bag of Words (BoW)",
        "definition": "A representation of text data where each document is represented as a set of words and their frequencies, disregarding grammar."
    },
    {
        "term": "Latent Dirichlet Allocation (LDA)",
        "definition": "A statistical model for topic modeling that classifies words in documents into different topics."
    },
    {
        "term": "Support Vector Machine (SVM)",
        "definition": "A supervised machine learning model that separates data into classes by finding the optimal hyperplane."
    },
    {
        "term": "Decision Tree",
        "definition": "A model used for classification and regression that splits data into branches to reach a decision based on certain conditions."
    },
    {
        "term": "Random Forest",
        "definition": "An ensemble learning technique that builds multiple decision trees and merges them to improve accuracy and reduce overfitting."
    },
    {
        "term": "K-Nearest Neighbors (KNN)",
        "definition": "A simple, instance-based learning algorithm that classifies data based on the closest neighbors in the feature space."
    },
    {
        "term": "Dimensionality Reduction",
        "definition": "Techniques used to reduce the number of features in a dataset, making it easier to process and visualize."
    }
];
